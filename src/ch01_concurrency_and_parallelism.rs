// 1.1 process
// process?
// 물질에는 사물과 프로세스가 있음. 사물은 공간상에서의 넓이(시간적x) 프로세스는 공간+시간의 넓이를 모두 가짐.
// e.g. 축구공 -> 사물, 축구경기 -> 특정 시점에 경기의 일부만 존재하는 시간적인 넓이를 가진 프로세스
//
// 프로그래밍에서의 process?
// -> 어떤 계산을 수행하는 추상적인 계산 실행 주체.
//
// 프로세스의 정의
// 계산을 실행하는 주체를 가리키며 다음 네가지 상태를 변경하면서 계산을 진행함.
// 1. 실행 전 상태: 계산을 실행하기 전의 상태. 실행 상태로 전이할 수 있다.
// 2. 실행 상태: 계산을 실행하고 있는 상태. 대기 상태 또는 계산 종료 상태로 전이할 수 있다.
// 3. 대기 상태: 계산을 일시적으로 정지한 상태, 실행 상태로 전이할 수 있다.
// 4. 종료 상태: 계산을 종료한 상태
// note_ 여기서 말하는 프로세스는 OS 프로세스보다 포괄적임. OS프로세스는 따로 OS를 접두사로 붙일 것임.
//
// 대기 상태로 전이하는 이유 세가지.
// 1. 데이터가 도착하기를 기다린다.
// 2. 계산 리소스 확보를 기다린다. 두 명의 수학자가 계산을 하기 위해서 자가 필요하다고 가정, 자는 하나뿐이고 한순간에
// 한명만 자를 이용할 수 있으니 다른 수학자는 기다릴 수 밖에 없음.
// 3. 자발적으로 대기상태로 진입. 타이머 등. 아무것도 할 필요가 없을 때 프로세스는 대기 상태가 됨. 이렇게 함으로써
// 계산 리소스를 불필요하게 점유하지 않게 됨.

// 1.2 concurrency
// 동시성? 2개 이상의 프로세스가 동시에 계산을 진행하는 상태.
// 먼저 실행 상태와 계산 중 상태를 구분해보자.
//               |           계산 중 상태            |
// 실행 전 상태 -> | 실행 상태 -> 대기 상태 -> 실행 상태 | -> 종료 상태
// 계산 중 상태는 대기 상태도 포괄함.
//
// 2개의 프로세스를 시간축에 따라 상태 전이도를 그려놓으면,
// 계산 중 상태가 겹치는 구간이 동시 실행 중이라고 할 수 있음(대기상태가 겹쳐도 동시 실행 중이다.)
//
// OS 프로세스 vs 스레드
// OS 프로세스는 커널에서 본 프로세스를 의미, 스레드는 OS 프로세스 안에 포함된 프로세스로 분류됨.
// e.g. 앱을 기동하면 하나(또는 소수)의 OS 프로세스가 생성되고, 그 OS프로세스 안에서 여러 스레드를 만듬.
// (프로세스 내부에 가상 메모리, 시스템 리소스(file descriptor), 스레드 등이 있음)
// OS 프로세스에서는 OS가 각 프로세스에 독립된 가상 메모리 공간을 할당하고, 각 스레드는 소속된 OS 프로세스의
// 가상 메모리 공간과 시스템 리소스를 공유함. -> 같은 OS 프로세스 내의 스레드 사이에서는 같은 file descriptor는
// 같은 파일을 가리키지만 다른 OS 프로세스 사이에서는 같은 file descriptor라도 다른 파일을 가리킴.
//
// 1.3 parallelism
// 프로세스 관점에서의 병렬성? 같은 시각에서 여러 프로세스가 동시에 계산을 실행하는 상태를 의미. 즉 여러 프로세스가
// 동시에 실행 중일 때 이를 병렬로 작동하고 있다고 함. concurrency와 다르게 실행상태가 겹치는 구간이 병렬 실행 중이라고 함.
// 컴퓨터 아키텍쳐, 하드웨어에서의 병렬성? 태스크 병렬성, 데이터 병렬성, 인스트럭션 레벨 병렬성 3종류로 나눔.
//
// 1.3.1 태스크 병렬성? 프로세스 관점의 병렬성과 같음. 다른말로 스레드 병렬성이라 부르기도 함.
// OS는 계산 처리를 OS프로세스 또는 스레드라 불리는 프로세스로 추상화하고 있으며,
// 태스크 병렬 처리에서는 OS 프로세스 또는 스레드를 여러 CPU를 이용해 동시에 작동시킴.
//
// 1.3.2 데이터 병렬성
// 데이터를 여러 개로 나눠서 병렬로 처리하는 방법. 이를 데이터 병렬 처리에서 벡터 연산이라 부름.
// e.g. Intel CPU의 AVX 명령은 벡터 연산용 명령어이며 GPU 내부에서는 벡터 연산 기반의 연산을 함.
//
// 데이터 병렬성은 CPU가 제공하는 벡터 연산 명령 이외의 방법으로도 구현가능.
// 벡터 간 덧셈을 1개의 스레드가 아니라 4개의 스레드로 실행하면 데이터 병렬성을 구현했다고 할 수 있음.
// -> 태스크 병렬성을 이용해 데이터 병렬성을 구현. but 스레드 생성이나 동기 처리를 위한 오버헤드를 염두에 둘 것.
//
// 응답 속도와 처리량
// 계산 속도는 응답 속도와 throughput의 두가지 척도로 생각해볼 수 있음. 응답 속도? 계산을 시작해서 마칠때까지의 시간.
// 응답 속도를 나타내기 위해 속비 CPU clock수나 소비 CPU instruction 수 등이 척도로 이용되는데 모두 시간으로 치환.
//
// 응답속도 = 소비 CPU clock 수 / CPU 작동 클록 주파수 [s]
// 응답속도 = 소비 CPU instruction 수 * Cycles Per Instruction / CPU 작동 클록 주파수 [s]
// CPI? 1인스트럭션당 평균 CPU 사이클 소비량.
// 주의점!
// CPI는 프로그램 종류에 따라 다름.
// CPU는 소비 전력을 억제하기 위해 작동 클록 주파수를 동적으로 변화시킬 수 있으므로, 위 식의 CPU 작동 클록 주파수에는
// 프로그램 실행 시의 작동 클록 주파수를 대입해야함.
//
// throughput? 단위 시간당 실행 가능한 계산량을 나타내며 단위는 MIPS(Million Instructions Per Second) 또는
// FLOPS(Floating Point Number Operations Per Second)
//
// 암달의 법칙(Amdhal's Law): 일부 처리의 병렬화가 전체적으로 고속화에 어느 정도 영향을 미치는지 예측하는 법칙
// 병렬화를 통한 응답 속도 향상 정도는 ([병렬화 가능한 처리 부분] / [병렬화 불가능한 처리 부분]) 그리고 병렬화를
// 위한 오버헤드에 따라 결정됨.
// 오버헤드가 없다면 이론상 속도는 순차실행이 병렬실행보다 빠를 순 없겠지만, 계산이 적거나 병렬화 불가능한 처리의 비율이
// 높을 때에는 병렬화과 순차 실행보다 오히려 느려질 수도 있다. 그러므로 데이터 병렬화를 할 때는 어느 정도의 정밀도로
// 병렬화할 것인지 충분히 고려해야함.
//
// 오버헤드가 없는 이상적인 암달의 법칙
// P = 병렬화 가능한 처리가 차지하는 비율, N = 병렬화 수 일때
// 성능 향상률 = 1 / ((1 - P) + P / N)
//
// 오버헤드를 고려한 현실적인 암달의 법칙
// H = 오버헤드의 응답 속도와 순차 실행했을때의 응답 속도의 비율
// 성능 향상률 = 1 / (H + (1 - P) + P / N)
//
// 1.3.3 인스트럭션 레벨 병렬성(instruction-level parallelism)
// 말그대로 CPU의 명령어 레벨에서 병렬화를 수행하는 방법. 주로 하드웨어나 컴파일러가 암묵적으로 수행하는 병렬화
// 대단히 높은 수준의 최적화를 할 때 사용. 사용례: 루프 전개 수행, data prefetch 수행 등.
// 루프는 전형적으로 조건문과 실제 실행을 수행하는 두 개의 구문으로 구성, 실제 실행문을 짧은 빈도로 반보갛면
// 조건문이 원인이 되어 인스트럭션 레벨 병렬성이 낮아지기도 함. 루프 전개를 해두면 이런 상황을 피할 수 있음.
//
// data prefetch는 미래에 메모리에 있는 데이터를 수행할 것을 미리 알고 있을 경우 사전에 데이터를 메모리에 읽어둠.
// 왜? IO(저장장치 -> 램 -> 캐시 -> cpu)는 cpu 계산보다 속도가 매우 느리기 때문. CPU에 나열된 인스트럭션 레벨
// 병렬화 기능에 의해 메모리를 읽는 중에도 다른 덧셈이나 뺄셈같은 연산 명령을 실행할 수 있기 때문에 메모리 읽기와
// 연산을 병렬 실행이 가능함. 일반적으로 memory prefetch라 부르며 명시적으로 지정할 수도 있다.
// 대부분 컴파일러가 알아서 최적화를 수행하기 때문에 명시적으로 지정하는 경우는 많지 않음.
//
// 인스트럭션 레벨 병렬화 방법 종류(파이프라인 처리, out-of-order, 투기적 실행)
// CPU 내부에서의 명령 실행 방법? 대부분의 CPU는 하나의 명령을 몇개의 단계로 나눠서 실행함 5개로 나눈다면 다음과 같음.
// 1) 명령 읽기(IF: Instruction Fetch) - 다음에 실행할 명령을 메모리에서 읽음
// 2) 명령 해석(ID: Instruction Decode) - 읽은 명령을 해석
// 3) 실행(EX: EXecution) - 실제 명령을 실행
// 4) 메모리 엑세스(MEM: MEMory access) - 메모리에 접근(읽기 또는 쓰기)
// 5) 쓰기(WB: Write Back) - 레지스터에 연산 결과를 씀.
// 이 분할된 단계를 pipeline stage라 부르며 분할한 수를 파이프라인 수라고 부름. 여기서 파이프라인 수는 5.
//
// 11011
// IF       ID      EX      MEM     WB
//          2+3
// IF       ID      EX      MEM     WB
//                  5
// IF       ID      EX      MEM     WB
//                      addr[1] = 5
// IF       ID      EX      MEM     WB
//                                $a = 5
// IF       ID      EX      MEM     WB
// -------------------------------------> 시간
// 클록1    클록2    클록3    클록4   클록5
//
// 위와 같은 파이프라인 처리는 종종 bucket relay(물을 길어 줄지어 나름)로 비유된다. 또한 CPU는 클록 사이클 단위로
// 처리를 진행하므로 시간 축에는 경과 클록 수를 표시함.
// 각 클록에서는 처리를 실행하는 단계 이외에는 아무것도 수행하지 않음.
// 버킷 릴레이에서는 여러 버킷을 사용하면 하나의 버킷을 사용해서 물을 나를 때보다 많은 양을 옮길 수 있지만,
// 파이프라인 처리에서도 버킷 릴레이와 마찬가지로 비어있는 단계에서도 동시 처리를 수행함으로써 여러 인스트럭션을
// 병렬로 실행함
//
// 명령 1] IF      ID      EX      MEM     WB
// 명령 2]         IF      ID      EX      MEM     WB
// 명령 3]                 IF      ID      EX      MEM     WB
// 명령 4]                         IF      ID      EX      MEM     WB
// ----------------------------------------------------------------> 경과 클록
//        1       2       3       4       5       6       7       8
//
// 위와 같이 병렬로 명령을 실행할 수 있으며, 단위 시간당 실행할 수 있는 명령어 수, 즉 처리량이 향상된다.
// 그러나 파이프라인 처리를 포함해 인스트럭션 레벨 병렬성으로는 응답 속도가 향상되지 않는다는 점에 주의해야 함.
// 또한 위에서는 8클록으로 4개의 명령을 병렬로 실행하므로 CPI는 8/4 = 2 이며 파이프라인 처리를 수행하지 않았을 때의
// CPI는 5다. 따라서 이 경우의 처리량은 5/2 = 2.5배 향상된다.
// 이론상 파이프라인 처리는 파이프라인 수의 배율(5)만큼 향상된다. 위의 예에서는 최대 5배까지 향상된다(상수 무시)
// 그러나 실제로는 데이터 의존 관계 등으로 인해 이론적인 배율만큼 되지 않는 경우가 대부분. 데이터 의존 관계 등의
// 원인으로 인스트럭션 레벨에서 병렬 실행할 수 없는 상태를 pipeline hazard라 부르며 CPU나 컴파일러는 각종
// 파이프라인 해저드에 대응한 처리를 해야함(데이터 레이스 등을 방지하기 위해 락을 걸어야하는 등 러스트의 소유권)
//
// pipeline hazard 3가지
// structural hazard: 하드웨어적으로 병렬 실행할 수 없는 명령을 실행했을 때 발생함.
// e.g. IF와 MEM이 모두 몌모리 접근을 수행한다고 했지만, 하드웨어적으로 동시에 메모리 접근을 할 수 없는경우?
// IF와 MEM을 병렬로 실행할 수 없어 구조 해저드 상태가 된다.
//
// data hazard: data 의존 관계가 있을 때 발생.
// e.g. 명령 1의 연산 결과를 명령 2에서 이어서 이용하는경우? 데이터 해저드 발생.
//
// control hazrd: 조건 분기가 있을 때 발생.
// e.g. 명령 1이 조건 분기고, 그 결과에 따라 명령 2의 실행 여부가 결정되는 경우 제어 해저드 상태가 됨.

// 1.4 동시 처리와 병렬 처리의 필요성
//
// 1.4.1 병렬 처리와 성능 향상
// 데이터 병렬성과 인스트럭션 레벨 병렬성은 소프트웨어 측에서는 크게 의식하지 않으며 컴파일러나 하드웨어가 암묵적으로
// 수행함. 하지만 task 병렬성은 multi-core CPU 또는 수백 개 단위의 many-core CPU로 인해 소프트웨어 측에서도
// 의식해야 하는 문제가 되었음. 소프트웨어 측에서도 병렬성을 의식하지 않으면 안되는 근본 원인은 하드웨어,
// 즉 반도체 기술의 기술적 한계에 있음.
//
// CPU 등의 chip은 얇은 원판 형태의 실리콘 위에 인쇄하는 구조. silicon wafer 위에 여러 die(CPU의 칩 등에 해당)
// 가 만들어진 형태이다.
//
// 반도체 소자의 미세화 기술(현시점 sota는 3나노)이 발전하면 실리콘 웨이퍼 위에 인쇄할 수 있는 회로 수가 많아져
// 동일 면적당 보다 많은 회로를 인쇄할 수 있음. 그러면 웨이퍼당 만들 수 있는 다이가 많아짐. 면적당 만들 수 있는
// 회로의 수가 많아지면 파이프라인 처리나 벡터 연산을 수행하는 복잡한 회로를 추가할 수 있음.
// 또한 웨이퍼당 만들 수 있는 다이 수가 많아지면 제조 단가가 낮아지는 이점이 있음.
// 게다가 반도체 소자를 미세화할수록 반도체로 만드는 트랜지스터를 빠르게 온오프할 수 있게 되어 CPU의 작동 클록을
// 높일 수 있다는 이점도 있음. 그러나 작동 주파수를 높이면 소비 전력도 높아져 발열도 높아짐 -> 열화가속, 작동 불안전.
// 소비 전력과 발열을 낮추기 위해 전압 또는 CPU의 작동 주파수를 낮추면 되지만 CPU 고속화를 위해 CPU의 작동 주파수를
// 낮추는 것은 본말이 전도(gos)되므로 일반적으로는 동작 주파수가 아니라 전압을 낮춤으로 소비전력과 발열 문제에 대처함.
// 이 방법은 효과적이었지만 반도체 소자가 너무 미세화되자 이제는 반도체 트랜지스터 안에서의 전류 누출이 문제가 되었음.
// 트랜지스터는 수도꼭지와 같은 것으로, 수도꼭지를 조작해 물이 흐르는 양(전류)를 변화시키는 장치임. 쉽게 말하면
// 수도꼭지를 열지 않았는데 물이 흘러나오거나 수도꼭지 자체에서 물이 샘. 전류누출이 많아지면 전력 낭비 + 발열 + 오작동.
// 이 전류 누출은 양자 터널 효과로 인해 일어나므로 해결하기 위해서는 반도체 소자를 키우거나 전압을 올려야함.
// 그러나 반도체 소자를 키우면 제조비용이 높아지고 작동 주파수가 낮아지며, 전압을 올리면 발열과 소비전력이 많아진다.
// 이처럼 반도체 소자의 미세화 발전, 작동 주파수, 소비전력, 발열, 누출 전류와 같은 문제들이 모두 한계에 이르렀음.
// 그 결과 CPU는 반도체 소자의 미세화와 작동 주파수의 고속화라는 방향에서 멀티코어나 매니코어 CPU의 방향으로 진화했음.
// 이런 변화의 흐름이 2000년 초반부터 중반까지이며 현재까지 이어졌음.
// 그래서 현재는 소프트웨어 측에서 병렬성을 반드시 고려해야하는 상황이 되었음.
//
// 1.4.2 동시 처리의 필요성과 계산 경로 수 급증
// 동시 처리가 중요한 이유? 효율적인 계산 리소스 활용, 공평성(공정성), 편리성의 세가지. 동시 처리가 가능하면
// IO 대기 상태 중에 다른 일을 할 수 있기 때문에 계산 리소스를 효율적으로 이용 가능.
//
// 동시 처리의 큰 특징으로 공평성을 들 수 있음. 이는 높은 편리성을 제공함.
// e.g. 스마트폰으로 음악을 들으며 웹서핑을 할 수 있는 이유는 스마트폰 위에서 작동하는 OS가 동시 처리 가능한
// 소프트웨어를 기반으로 하기 때문.
//
// 동시 처리는 효율이 좋고 편리한 반면 복잡성이라는 문제점을 안고 있음.
// e.g. 4개의 프로세스 a, b, c, d가 있다고 가정. 여기서 각 프로세스가 동시에 작동하지만 병렬로 작동하지는 않을 때
// 각 프로세스의 실행패턴은 어떻게 될까(a, b, c, d 순으로 실행됨)? 순서가 일정하지 않음
// 계산 트리(computation tree)로 나타내면 24개의 경우의 수가 있음(n!). 만약 n!개의 패턴 중 몇개에 버그가
// 존재한다면? 재현성이 매우 낮은 희소한 버그가 된다는 것을 의미. n = 10만 되어도 계산 경로 수가 3628800개까지 증가.
//
// 동시 처리는 이런 복잡성, 즉 계산 경로 수의 급증이라는 문제를 안고 있음. 그렇기 때문에 두서없이 병렬 프로그래밍
// 기술로 동시성 프로그래밍을 하게 되면 이런 함정에 쉽게 빠질 수 있음. 이런 상황에 놓이지 않기 위해 동시성 프로그래밍
// 작동 원리와 이론 모델을 학습하고 버그를 줄이고 편리성을 유지하면서도 병렬로 고속 작동하는 소프트웨어를 구현하는
// 기술을 익혀야함.
